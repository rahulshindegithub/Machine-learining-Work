{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ac8502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Paragraph = \"This is the NLP session that is going on and finally we are happy. iNeuron is a company where we teach all tech\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f0fcdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a80e10f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = nltk.sent_tokenize(Paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42767b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'the',\n",
       " 'NLP',\n",
       " 'session',\n",
       " 'that',\n",
       " 'is',\n",
       " 'going',\n",
       " 'on',\n",
       " 'and',\n",
       " 'finally',\n",
       " 'we',\n",
       " 'are',\n",
       " 'happy',\n",
       " '.',\n",
       " 'iNeuron',\n",
       " 'is',\n",
       " 'a',\n",
       " 'company',\n",
       " 'where',\n",
       " 'we',\n",
       " 'teach',\n",
       " 'all',\n",
       " 'tech']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tokenization\n",
    "nltk.word_tokenize(Paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cdc79e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ceb4287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'histori'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Stemming :-\n",
    "## it is nothin but chenge the mining of the word\n",
    "\n",
    "stemmer.stem(\"history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "618946e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'organ'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"organization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "546176ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happi'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"happy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a92258f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b6168f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79439e05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mlemmatizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlemmatize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhistorical\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\stem\\wordnet.py:45\u001b[0m, in \u001b[0;36mWordNetLemmatizer.lemmatize\u001b[1;34m(self, word, pos)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlemmatize\u001b[39m(\u001b[38;5;28mself\u001b[39m, word: \u001b[38;5;28mstr\u001b[39m, pos: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;124;03m\"\"\"Lemmatize `word` using WordNet's built-in morphy function.\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m    Returns the input word unchanged if it cannot be found in WordNet.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;03m    :return: The lemma of `word`, for the given `pos`.\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m     lemmas \u001b[38;5;241m=\u001b[39m \u001b[43mwn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_morphy\u001b[49m(word, pos)\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(lemmas, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m lemmas \u001b[38;5;28;01melse\u001b[39;00m word\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py:89\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# This is where the magic happens!  Transform ourselves into\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# the corpus by modifying our own __dict__ and __class__ to\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# match that of the corpus.\u001b[39;00m\n\u001b[0;32m     95\u001b[0m args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py:1176\u001b[0m, in \u001b[0;36mWordNetCorpusReader.__init__\u001b[1;34m(self, root, omw_reader)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe multilingual functions are not available with this Wordnet version\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1174\u001b[0m     )\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprovenances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43momw_prov\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;66;03m# A cache to store the wordnet data of multiple languages\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lang_data \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py:1285\u001b[0m, in \u001b[0;36mWordNetCorpusReader.omw_prov\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1283\u001b[0m provdict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1284\u001b[0m provdict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meng\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1285\u001b[0m fileids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_omw_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfileids\u001b[49m()\n\u001b[0;32m   1286\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fileid \u001b[38;5;129;01min\u001b[39;00m fileids:\n\u001b[0;32m   1287\u001b[0m     prov, langfile \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplit(fileid)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m         root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py:555\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    553\u001b[0m modified_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(pieces[:i] \u001b[38;5;241m+\u001b[39m [pieces[i] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m pieces[i:])\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodified_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py:542\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(p):\n\u001b[0;32m    541\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mZipFilePathPointer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzipentry\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m    544\u001b[0m         \u001b[38;5;66;03m# resource not in zipfile\u001b[39;00m\n\u001b[0;32m    545\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\compat.py:41\u001b[0m, in \u001b[0;36mpy3_data.<locals>._decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decorator\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     40\u001b[0m     args \u001b[38;5;241m=\u001b[39m (args[\u001b[38;5;241m0\u001b[39m], add_py3_data(args[\u001b[38;5;241m1\u001b[39m])) \u001b[38;5;241m+\u001b[39m args[\u001b[38;5;241m2\u001b[39m:]\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m init_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py:394\u001b[0m, in \u001b[0;36mZipFilePathPointer.__init__\u001b[1;34m(self, zipfile, entry)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;124;03mCreate a new path pointer pointing at the specified entry\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;124;03min the given zipfile.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03mdoes not contain the specified entry.\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(zipfile, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 394\u001b[0m     zipfile \u001b[38;5;241m=\u001b[39m \u001b[43mOpenOnDemandZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzipfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;66;03m# Check that the entry exists:\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m entry:\n\u001b[0;32m    398\u001b[0m \n\u001b[0;32m    399\u001b[0m     \u001b[38;5;66;03m# Normalize the entry string, it should be relative:\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\compat.py:41\u001b[0m, in \u001b[0;36mpy3_data.<locals>._decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decorator\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     40\u001b[0m     args \u001b[38;5;241m=\u001b[39m (args[\u001b[38;5;241m0\u001b[39m], add_py3_data(args[\u001b[38;5;241m1\u001b[39m])) \u001b[38;5;241m+\u001b[39m args[\u001b[38;5;241m2\u001b[39m:]\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m init_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py:935\u001b[0m, in \u001b[0;36mOpenOnDemandZipFile.__init__\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filename, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReopenableZipFile filename must be a string\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 935\u001b[0m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    936\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;241m==\u001b[39m filename\n\u001b[0;32m    937\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\zipfile.py:1266\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[0;32m   1264\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m-> 1266\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_RealGetContents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1267\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   1268\u001b[0m         \u001b[38;5;66;03m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[0;32m   1269\u001b[0m         \u001b[38;5;66;03m# even if no files are added to the archive\u001b[39;00m\n\u001b[0;32m   1270\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_didModify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\zipfile.py:1333\u001b[0m, in \u001b[0;36mZipFile._RealGetContents\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1331\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m endrec:\n\u001b[1;32m-> 1333\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1335\u001b[0m     \u001b[38;5;28mprint\u001b[39m(endrec)\n",
      "\u001b[1;31mBadZipFile\u001b[0m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"historical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "191e019d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is the NLP session that is going on and finally we are happy.',\n",
       " 'iNeuron is a company where we teach all tech']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d1a92d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'the', 'NLP', 'session', 'that', 'is', 'going', 'on', 'and', 'finally', 'we', 'are', 'happy', '.']\n",
      "['iNeuron', 'is', 'a', 'company', 'where', 'we', 'teach', 'all', 'tech']\n"
     ]
    }
   ],
   "source": [
    "corpus=[]\n",
    "for i in range(len(sentence)):\n",
    "    word=nltk.word_tokenize(sentence[i])\n",
    "    print(word)\n",
    "    corpus.append(' '.join(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ac69e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is the NLP session that is going on and finally we are happy .',\n",
       " 'iNeuron is a company where we teach all tech']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47bb28df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thi', 'is', 'the', 'nlp', 'session', 'that', 'is', 'go', 'on', 'and', 'final', 'we', 'are', 'happi', '.']\n",
      "['ineuron', 'is', 'a', 'compani', 'where', 'we', 'teach', 'all', 'tech']\n"
     ]
    }
   ],
   "source": [
    "corpu=[]\n",
    "for i in range(len(sentence)):\n",
    "    words=nltk.word_tokenize(sentence[i])\n",
    "    words=[stemmer.stem(word) for word in words]\n",
    "    print(words)\n",
    "    corpu.append(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8834cfb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea8edfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b04bb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "para = '''\n",
    "Ratan Naval Tata (born 28 December 1937) is an Indian industrialist and former chairman of Tata Sons. He was also the chairman of the Tata Group from 1990 to 2012, serving also as interim chairman from October 2016 through February 2017. He continues to head its charitable trusts.[2][3] In 2008, he received the Padma Vibhushan, the second highest civilian honour in India, after receiving the Padma Bhushan, the third highest civilian honour in 2000.[4]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23318ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRatan Naval Tata (born 28 December 1937) is an Indian industrialist and former chairman of Tata Sons. He was also the chairman of the Tata Group from 1990 to 2012, serving also as interim chairman from October 2016 through February 2017. He continues to head its charitable trusts.[2][3] In 2008, he received the Padma Vibhushan, the second highest civilian honour in India, after receiving the Padma Bhushan, the third highest civilian honour in 2000.[4]\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a6fac05",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = nltk.sent_tokenize(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "376de1f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nRatan Naval Tata (born 28 December 1937) is an Indian industrialist and former chairman of Tata Sons.',\n",
       " 'He was also the chairman of the Tata Group from 1990 to 2012, serving also as interim chairman from October 2016 through February 2017.',\n",
       " 'He continues to head its charitable trusts.',\n",
       " '[2][3] In 2008, he received the Padma Vibhushan, the second highest civilian honour in India, after receiving the Padma Bhushan, the third highest civilian honour in 2000.',\n",
       " '[4]']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a167896f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ratan', 'naval', 'tata', '(', 'born', '28', 'decemb', '1937', ')', 'is', 'an', 'indian', 'industrialist', 'and', 'former', 'chairman', 'of', 'tata', 'son', '.']\n",
      "['he', 'wa', 'also', 'the', 'chairman', 'of', 'the', 'tata', 'group', 'from', '1990', 'to', '2012', ',', 'serv', 'also', 'as', 'interim', 'chairman', 'from', 'octob', '2016', 'through', 'februari', '2017', '.']\n",
      "['he', 'continu', 'to', 'head', 'it', 'charit', 'trust', '.']\n",
      "['[', '2', ']', '[', '3', ']', 'in', '2008', ',', 'he', 'receiv', 'the', 'padma', 'vibhushan', ',', 'the', 'second', 'highest', 'civilian', 'honour', 'in', 'india', ',', 'after', 'receiv', 'the', 'padma', 'bhushan', ',', 'the', 'third', 'highest', 'civilian', 'honour', 'in', '2000', '.']\n",
      "['[', '4', ']']\n"
     ]
    }
   ],
   "source": [
    "corpu=[]\n",
    "for i in range(len(sentence)):\n",
    "    words=nltk.word_tokenize(sentence[i])\n",
    "    words=[stemmer.stem(word) for word in words]\n",
    "    print(words)\n",
    "    corpu.append(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ebd1755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ratan naval tata ( born 28 decemb 1937 ) is an indian industrialist and former chairman of tata son .',\n",
       " 'he wa also the chairman of the tata group from 1990 to 2012 , serv also as interim chairman from octob 2016 through februari 2017 .',\n",
       " 'he continu to head it charit trust .',\n",
       " '[ 2 ] [ 3 ] in 2008 , he receiv the padma vibhushan , the second highest civilian honour in india , after receiv the padma bhushan , the third highest civilian honour in 2000 .',\n",
       " '[ 4 ]']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b560791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ratan', 'naval', 'tata', '(', 'born', '28', 'decemb', '1937', ')', 'is', 'an', 'indian', 'industrialist', 'and', 'former', 'chairman', 'of', 'tata', 'son', '.']\n",
      "['he', 'wa', 'also', 'the', 'chairman', 'of', 'the', 'tata', 'group', 'from', '1990', 'to', '2012', ',', 'serv', 'also', 'as', 'interim', 'chairman', 'from', 'octob', '2016', 'through', 'februari', '2017', '.']\n",
      "['he', 'continu', 'to', 'head', 'it', 'charit', 'trust', '.']\n",
      "['[', '2', ']', '[', '3', ']', 'in', '2008', ',', 'he', 'receiv', 'the', 'padma', 'vibhushan', ',', 'the', 'second', 'highest', 'civilian', 'honour', 'in', 'india', ',', 'after', 'receiv', 'the', 'padma', 'bhushan', ',', 'the', 'third', 'highest', 'civilian', 'honour', 'in', '2000', '.']\n",
      "['[', '4', ']']\n"
     ]
    }
   ],
   "source": [
    "corpu=[]\n",
    "for i in range(len(sentence)):\n",
    "    words=nltk.word_tokenize(sentence[i])\n",
    "    words=[stemmer.stem(word) for word in words]\n",
    "    print(words)\n",
    "    corpu.append(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e6c4777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ratan naval tata ( born 28 decemb 1937 ) is an indian industrialist and former chairman of tata son .',\n",
       " 'he wa also the chairman of the tata group from 1990 to 2012 , serv also as interim chairman from octob 2016 through februari 2017 .',\n",
       " 'he continu to head it charit trust .',\n",
       " '[ 2 ] [ 3 ] in 2008 , he receiv the padma vibhushan , the second highest civilian honour in india , after receiv the padma bhushan , the third highest civilian honour in 2000 .',\n",
       " '[ 4 ]']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30bf728d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97606381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: click in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: joblib in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18ee7733",
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "660620bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nRatan Naval Tata (born 28 December 1937) is an Indian industrialist and former chairman of Tata Sons.',\n",
       " 'He was also the chairman of the Tata Group from 1990 to 2012, serving also as interim chairman from October 2016 through February 2017.',\n",
       " 'He continues to head its charitable trusts.',\n",
       " '[2][3] In 2008, he received the Padma Vibhushan, the second highest civilian honour in India, after receiving the Padma Bhushan, the third highest civilian honour in 2000.',\n",
       " '[4]']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "705ea9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ratan', 'naval', 'tata', 'born', '28', 'decemb', '1937', 'is', 'an', 'indian', 'industrialist', 'and', 'former', 'chairman', 'of', 'tata', 'son']\n",
      "['he', 'wa', 'also', 'the', 'chairman', 'of', 'the', 'tata', 'group', 'from', '199', 'to', '2', '12', 'serv', 'also', 'as', 'interim', 'chairman', 'from', 'octob', '2', '16', 'through', 'februari', '2', '17']\n",
      "['he', 'continu', 'to', 'head', 'it', 'charit', 'trust']\n",
      "['2', '3', 'in', '2', '8', 'he', 'receiv', 'the', 'padma', 'vibhushan', 'the', 'second', 'highest', 'civilian', 'honour', 'in', 'india', 'after', 'receiv', 'the', 'padma', 'bhushan', 'the', 'third', 'highest', 'civilian', 'honour', 'in', '2']\n",
      "['4']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "corpu=[]\n",
    "for i in range(len(sentence)):\n",
    "    text= re.sub('[^a-zA-Z1-9]',' ',sentence[i])\n",
    "    text=text.lower()\n",
    "    words=text.split()\n",
    "    words=[stemmer.stem(word) for word in words]\n",
    "    print(words)\n",
    "    corpu.append(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aec9b9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ratan naval tata born 28 decemb 1937 is an indian industrialist and former chairman of tata son',\n",
       " 'he wa also the chairman of the tata group from 199 to 2 12 serv also as interim chairman from octob 2 16 through februari 2 17',\n",
       " 'he continu to head it charit trust',\n",
       " '2 3 in 2 8 he receiv the padma vibhushan the second highest civilian honour in india after receiv the padma bhushan the third highest civilian honour in 2',\n",
       " '4']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50fc4a47",
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "93f4edee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer(binary=True,ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f1730509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x112 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 120 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit_transform(corpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f220e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "        0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0],\n",
       "       [1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "        0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "        1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "        0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "        0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### applied BOW\n",
    "cv.fit_transform(corpu).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "175d921a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 112)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit_transform(corpu).toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd7b8ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ratan': 81,\n",
       " 'naval': 71,\n",
       " 'tata': 90,\n",
       " 'born': 24,\n",
       " '28': 9,\n",
       " 'decemb': 35,\n",
       " '1937': 5,\n",
       " 'is': 67,\n",
       " 'an': 16,\n",
       " 'indian': 61,\n",
       " 'industrialist': 63,\n",
       " 'and': 18,\n",
       " 'former': 39,\n",
       " 'chairman': 26,\n",
       " 'of': 75,\n",
       " 'son': 89,\n",
       " 'ratan naval': 82,\n",
       " 'naval tata': 72,\n",
       " 'tata born': 91,\n",
       " 'born 28': 25,\n",
       " '28 decemb': 10,\n",
       " 'decemb 1937': 36,\n",
       " '1937 is': 6,\n",
       " 'is an': 68,\n",
       " 'an indian': 17,\n",
       " 'indian industrialist': 62,\n",
       " 'industrialist and': 64,\n",
       " 'and former': 19,\n",
       " 'former chairman': 40,\n",
       " 'chairman of': 28,\n",
       " 'of tata': 76,\n",
       " 'tata son': 93,\n",
       " 'he': 46,\n",
       " 'wa': 110,\n",
       " 'also': 13,\n",
       " 'the': 94,\n",
       " 'group': 44,\n",
       " 'from': 41,\n",
       " '199': 7,\n",
       " 'to': 104,\n",
       " '12': 0,\n",
       " 'serv': 87,\n",
       " 'as': 20,\n",
       " 'interim': 65,\n",
       " 'octob': 73,\n",
       " '16': 2,\n",
       " 'through': 102,\n",
       " 'februari': 37,\n",
       " '17': 4,\n",
       " 'he wa': 49,\n",
       " 'wa also': 111,\n",
       " 'also the': 15,\n",
       " 'the chairman': 95,\n",
       " 'of the': 77,\n",
       " 'the tata': 98,\n",
       " 'tata group': 92,\n",
       " 'group from': 45,\n",
       " 'from 199': 42,\n",
       " '199 to': 8,\n",
       " 'to 12': 105,\n",
       " '12 serv': 1,\n",
       " 'serv also': 88,\n",
       " 'also as': 14,\n",
       " 'as interim': 21,\n",
       " 'interim chairman': 66,\n",
       " 'chairman from': 27,\n",
       " 'from octob': 43,\n",
       " 'octob 16': 74,\n",
       " '16 through': 3,\n",
       " 'through februari': 103,\n",
       " 'februari 17': 38,\n",
       " 'continu': 33,\n",
       " 'head': 50,\n",
       " 'it': 69,\n",
       " 'charit': 29,\n",
       " 'trust': 107,\n",
       " 'he continu': 47,\n",
       " 'continu to': 34,\n",
       " 'to head': 106,\n",
       " 'head it': 51,\n",
       " 'it charit': 70,\n",
       " 'charit trust': 30,\n",
       " 'in': 56,\n",
       " 'receiv': 83,\n",
       " 'padma': 78,\n",
       " 'vibhushan': 108,\n",
       " 'second': 85,\n",
       " 'highest': 52,\n",
       " 'civilian': 31,\n",
       " 'honour': 54,\n",
       " 'india': 59,\n",
       " 'after': 11,\n",
       " 'bhushan': 22,\n",
       " 'third': 100,\n",
       " 'in he': 57,\n",
       " 'he receiv': 48,\n",
       " 'receiv the': 84,\n",
       " 'the padma': 96,\n",
       " 'padma vibhushan': 80,\n",
       " 'vibhushan the': 109,\n",
       " 'the second': 97,\n",
       " 'second highest': 86,\n",
       " 'highest civilian': 53,\n",
       " 'civilian honour': 32,\n",
       " 'honour in': 55,\n",
       " 'in india': 58,\n",
       " 'india after': 60,\n",
       " 'after receiv': 12,\n",
       " 'padma bhushan': 79,\n",
       " 'bhushan the': 23,\n",
       " 'the third': 99,\n",
       " 'third highest': 101}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_   ### this is feture index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2280d018",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d0750feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf=TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "938460b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.24321258, 0.        ,\n",
       "        0.24321258, 0.        , 0.        , 0.24321258, 0.24321258,\n",
       "        0.        , 0.        , 0.24321258, 0.19622238, 0.        ,\n",
       "        0.        , 0.        , 0.24321258, 0.        , 0.24321258,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.24321258, 0.24321258,\n",
       "        0.        , 0.24321258, 0.        , 0.24321258, 0.        ,\n",
       "        0.19622238, 0.        , 0.24321258, 0.        , 0.        ,\n",
       "        0.        , 0.24321258, 0.39244476, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.19031713, 0.19031713, 0.19031713, 0.        , 0.19031713,\n",
       "        0.        , 0.        , 0.38063426, 0.        , 0.        ,\n",
       "        0.19031713, 0.        , 0.        , 0.30709333, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.19031713, 0.        ,\n",
       "        0.38063426, 0.19031713, 0.1274576 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.19031713, 0.        , 0.        , 0.        , 0.19031713,\n",
       "        0.15354666, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.19031713, 0.        , 0.15354666, 0.30709333, 0.        ,\n",
       "        0.19031713, 0.15354666, 0.        , 0.        , 0.19031713],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.40490709,\n",
       "        0.        , 0.40490709, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.271171  , 0.40490709, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.40490709, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.32667649, 0.40490709, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.14766173, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.14766173, 0.        , 0.        , 0.        ,\n",
       "        0.29532347, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.09889078, 0.        , 0.29532347,\n",
       "        0.29532347, 0.4429852 , 0.14766173, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.29532347, 0.        , 0.29532347, 0.14766173,\n",
       "        0.        , 0.        , 0.        , 0.47653023, 0.14766173,\n",
       "        0.        , 0.        , 0.        , 0.14766173, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf.fit_transform(corpu).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c2a5592c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ratan': 37,\n",
       " 'naval': 33,\n",
       " 'tata': 42,\n",
       " 'born': 12,\n",
       " '28': 5,\n",
       " 'decemb': 17,\n",
       " '1937': 3,\n",
       " 'is': 31,\n",
       " 'an': 8,\n",
       " 'indian': 28,\n",
       " 'industrialist': 29,\n",
       " 'and': 9,\n",
       " 'former': 19,\n",
       " 'chairman': 13,\n",
       " 'of': 35,\n",
       " 'son': 41,\n",
       " 'he': 22,\n",
       " 'wa': 49,\n",
       " 'also': 7,\n",
       " 'the': 43,\n",
       " 'group': 21,\n",
       " 'from': 20,\n",
       " '199': 4,\n",
       " 'to': 46,\n",
       " '12': 0,\n",
       " 'serv': 40,\n",
       " 'as': 10,\n",
       " 'interim': 30,\n",
       " 'octob': 34,\n",
       " '16': 1,\n",
       " 'through': 45,\n",
       " 'februari': 18,\n",
       " '17': 2,\n",
       " 'continu': 16,\n",
       " 'head': 23,\n",
       " 'it': 32,\n",
       " 'charit': 14,\n",
       " 'trust': 47,\n",
       " 'in': 26,\n",
       " 'receiv': 38,\n",
       " 'padma': 36,\n",
       " 'vibhushan': 48,\n",
       " 'second': 39,\n",
       " 'highest': 24,\n",
       " 'civilian': 15,\n",
       " 'honour': 25,\n",
       " 'india': 27,\n",
       " 'after': 6,\n",
       " 'bhushan': 11,\n",
       " 'third': 44}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95f6711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8356eb34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### new test data\n",
    "data=[\"I want to have food\"] ## this is word to vect\n",
    "\n",
    "cv.transform(data).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade5c6b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811d06fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df1964e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
